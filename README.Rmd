---
output: github_document
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "man/figures/README-",
  out.width = "100%",
  dpi = 300
)
```

# openalexR <img src="man/figures/logo.png" align="right" height="139"/>

<!-- badges: start -->

[![R-CMD-check](https://github.com/massimoaria/openalexR/actions/workflows/R-CMD-check.yaml/badge.svg)](https://github.com/massimoaria/openalexR/actions/workflows/R-CMD-check.yaml) 
[![Lifecycle: experimental](https://img.shields.io/badge/lifecycle-experimental-orange.svg)](https://lifecycle.r-lib.org/articles/stages.html#experimental)
[![CRAN status](https://www.r-pkg.org/badges/version/openalexR)](https://CRAN.R-project.org/package=openalexR)
`r badger::badge_cran_download("openalexR", "grand-total")` 

<!-- badges: end -->

**openalexR** helps you interface with the [OpenAlex](https://openalex.org) API to retrieve bibliographic infomation about publications, authors, venues, institutions and concepts with 5 main functions:

-   `oa_fetch()`: composes three functions below so the user can execute everything in one step, *i.e.*, `oa_query |> oa_request |> oa2df`

-   `oa_query()`: generates a valid query, written following the OpenAlex API syntax, from a set of arguments provided by the user.

-   `oa_request()`: downloads a collection of entities matching the query created by `oa_query()` or manually written by the user, and returns a JSON object in a list format.

-   `oa2df()`: converts the JSON object in classical bibliographic tibble/data frame.

-   `oa_random()`: get random entity, _e.g._, `oa_random("works")` gives a different work each time you run it

## Setup

You can install the developer version of openalexR from [GitHub](https://github.com) with:

```{r eval=FALSE}
install.packages("remotes")
remotes::install_github("massimoaria/openalexR")
```

You can install the released version of openalexR from [CRAN](https://CRAN.R-project.org) with:

```{r eval=FALSE}
install.packages("openalexR")
```

Before we go any further, we highly recommend you set `openalexR.mailto` option so that your requests go to [the polite pool](https://docs.openalex.org/api#the-polite-pool) for faster response times:

```{r}
options(openalexR.mailto = "example@email.com")
```

Bonus point if you put this in your `.Rprofile` with `file.edit("~/.Rprofile")`.

```{r warning=FALSE, message=FALSE}
library(openalexR)
library(dplyr)
library(ggplot2)
theme_set(theme_classic())
```

## Examples

There are different [filters](https://docs.openalex.org/api/get-lists-of-entities/filter-entity-lists)/arguments you can use in `oa_fetch`, depending on which [entity](https://docs.openalex.org/about-the-data) you're interested in: works, authors, venues, institutions, or concepts.
We show a few examples below.

### Works

**Goal**: Download all information about a givens set of publications (known DOIs).

Use `doi` as a [works filter](https://docs.openalex.org/api/get-lists-of-entities/filter-entity-lists#works-filters) (either the canonical form with <https://doi.org/> or without):

```{r}
oa_fetch(
  doi = c("10.1016/j.joi.2017.08.007", "https://doi.org/10.1093/bioinformatics/btab727"),
  entity = "works",
  verbose = TRUE
) %>% 
  show_works() %>%
  knitr::kable()
```

**Goal**: Download all works published by a set of authors (known ORCIDs).

Use `author.orcid` as a filter (for now, we need to provide the canonical form with <https://orcid.org/>):

```{r}
orcids <- c("0000-0003-3737-6565", "0000-0002-8517-9411")
canonical_orcids <- paste0("https://orcid.org/", orcids)
oa_fetch(
  entity = "works",
  author.orcid = canonical_orcids,
  verbose = TRUE
) %>% 
  show_works() %>% 
  knitr::kable()
```

**Goal**: Download all works that have been cited more than 50 times, published between 2020 and 2021, and include the strings "bibliometric analysis" or "science mapping" in the title.
Maybe we also want the results to be sorted by total citations in a descending order.

```{r}
oa_fetch(
  entity = "works",
  title.search = c("bibliometric analysis", "science mapping"),
  cited_by_count = ">50", 
  from_publication_date = "2020-01-01",
  to_publication_date = "2021-12-31",
  sort = "cited_by_count:desc",
  verbose = TRUE
) %>%
  show_works() %>%
  knitr::kable()
```

### Authors

**Goal**: Download author information when we know their ORCID.

Here, instead of `author.orcid` like earlier, we have to use `orcid` as an argument.
This may be a little confusing, but again, a different entity (**authors** instead of **works**) requires a [different set of filters](https://docs.openalex.org/api/get-lists-of-entities/filter-entity-lists#authors-filters).

```{r}
oa_fetch(
  entity = "authors",
  orcid = c("0000-0003-3737-6565", "0000-0002-8517-9411")
) %>%
  show_authors() %>%
  knitr::kable()
```

**Goal**: Acquire information on the authors of this package.

We can filter by other [filters](https://docs.openalex.org/api/get-lists-of-entities/filter-entity-lists#authors-filters) such as `display_name` and `has_orcid`:

```{r}
oa_fetch(
  entity = "authors",
  display_name = c("Massimo Aria", "Trang T. Le"),
  has_orcid = "true"
) %>%
  show_authors() %>%
  knitr::kable()
```

**Goal**: Download all authors' records of scholars who work at the [University of Naples Federico II](https://explore.openalex.org/institutions/I71267560) (OpenAlex ID: I71267560) and have published at least 500 publications.

Let's first check how many records match the query, then download the entire collection.
We can do this by first defining a list of arguments, then adding `count_only` (default `FALSE`) to this list:

```{r}
my_arguments <- list(
  entity = "authors",
  last_known_institution.id = "I71267560",
  works_count = ">499"
)

do.call(oa_fetch, c(my_arguments, list(count_only = TRUE)))
do.call(oa_fetch, my_arguments) %>% 
  show_authors() %>%
  knitr::kable()
```

## Example analyses

**Goal**: track the popularity of *Biology* concepts over time.

We first download the records of all level-1 concepts/keywords that concern over one million works:

```{r biological-concepts}
library(gghighlight)
concept_df <- oa_fetch(
  entity = "concepts",
  level = 1,
  ancestors.id = "https://openalex.org/C86803240", # Biology
  works_count = ">1000000"
)

concept_df %>% 
  select(display_name, counts_by_year) %>% 
  tidyr::unnest(counts_by_year) %>% 
  filter(year < 2022) %>% 
  ggplot() +
  aes(x = year, y = works_count, color = display_name) +
  facet_wrap(~ display_name) +
  geom_line(size = 0.7) +
  scale_color_brewer(palette = "Dark2") +
  labs(x = NULL, y = "Works count",
       title = "We know what happened in 2020.") +
  guides(color = "none") +
  gghighlight(max(works_count) > 99500) +
  NULL
```

**Goal**: Rank institutions in Italy by total number of citations.

We want download all records regarding Italian institutions (country_code:it) that are classified as educational (type:education).
Again, we check how many records match the query then download the collection:

```{r italy-insts, fig.height=3.5, fig.width=7}
italy_insts <- oa_fetch(
  entity = "institutions",
  country_code = "it",
  type = "education",
  verbose = TRUE
)

italy_insts %>% 
  slice_max(cited_by_count, n = 8) %>% 
  mutate(display_name = forcats::fct_reorder(display_name, cited_by_count)) %>%
  ggplot() +
  aes(x = cited_by_count, y = display_name, fill = display_name) +
  geom_col() +
  scale_fill_viridis_d(option = "E") +
  guides(fill = "none") +
  labs(x = "Total citations", y = NULL,
       title = "Italian references.") +
  coord_cartesian(expand = FALSE)
```

**Goal**: Visualize big journals' topics.

We first download all records regarding journals that have published more than 300,000 works, then visualize their scored concepts:

```{r big-journals, fig.height=8, fig.width=8}
jours <- oa_fetch(
  entity = "venues",
  works_count = ">300000",
  verbose = TRUE
)

jours %>% 
  distinct(display_name, .keep_all = TRUE) %>% 
  select(jour = display_name, x_concepts) %>% 
  tidyr::unnest(x_concepts) %>% 
  filter(level == 0) %>% 
  tidyr::complete(jour, display_name, fill = list(score = 0)) %>% 
  group_by(jour) %>% 
  ggplot() +
  aes(fill = jour, y = score, x= display_name, group = jour) +
  facet_wrap(~ jour) +
  geom_col(color = "grey20") +
  coord_polar(clip = "off") +
  theme_bw() +
  theme(axis.text.y = element_blank(),
        axis.ticks.y = element_blank(),
        axis.text.x = element_text(size = 8)) +
  scale_fill_brewer(palette = "Set1") +
  scale_y_continuous(breaks = 50) +
  guides(fill = "none") +
  labs(y = NULL, x = NULL,
       title = "Journal clocks.")
```

## Snowball search

TODO

## About OpenAlex

![oar-img](man/figures/oar.jpeg)

::: {style="text-align: right"}
Schema credits: [\@dhimmel](https://github.com/dhimmel)
:::

[OpenAlex](https://openalex.org) is a fully open catalog of the global research system.
It's named after the ancient [Library of Alexandria](https://en.wikipedia.org/wiki/Library_of_Alexandria).
The OpenAlex dataset describes scholarly entities and how those entities are connected to each other.
There are five types of entities:

-   **Works** are papers, books, datasets, etc; they cite other works

-   **Authors** are people who create works

-   **Venues** are journals and repositories that host works

-   **Institutions** are universities and other orgs that are affiliated with works (via authors)

-   **Concepts** *tag* Works with a topic

## Acknowledgements

Package hex was made with [Midjourney](https://www.midjourney.com/home/) and thus inherits a [CC BY-NC 4.0 license](https://creativecommons.org/licenses/by-nc/4.0/legalcode).
